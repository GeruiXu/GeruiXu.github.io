---
layout: page
permalink: /Research/index.html
title: Research
---

Latest Update: 20th Oct 2023&nbsp; 

During my professional experience with enterprise-level automated vehicle projects, I specialized in multidimensional data analysis. This involved not only extracting and processing large datasets from real vehicles but also integrating and analyzing eye-tracking data of drivers. Such comprehensive data handling equipped me with a unique perspective on human-machine interaction, specifically in understanding and optimizing takeover behavior in autonomous driving.

## Journal Paper

- Zhenhua Yu, <font color='red'>Gerui Xu</font>, Kang Jiang, Zhongxiang Feng, Shan Xu. (2023). Constructing the behavioral sequence of the takeover process—TOR, behavior characteristics and phases division: A real vehicle experiment. Accident Analysis & Prevention, 186, 107040. 

  [Access article](https://doi.org/10.1016/j.aap.2023.107040)
  
  <br>

---

## Graduate Projects

### Jun 2022 – Present<br>

**"Dynamic Transfer Patterns of Takeover Behavior in Autonomous Driving and Methods for Enhancing Takeover Performance"**<br>National Natural Science Foundation of China (Grant Nos. 52172344)

Supervised by **Prof. Kang Jiang**



### Sep 2021 – Dec 2022 

**"Mechanism of Visual Focus Transfer and Method of Human-Computer Interaction of Wake-up Attention As Take-over in Highly Automated Driving"** <br>National Natural Science Foundation Youth Fund (Grant Nos. 51905142)

Supervised by **Dr. Zhenhua Yu**

> 

### Aug 2022 – Present 

**"Spatial Object Recognition and Tracking Localization Based on Augmented Reality"** <br>(2022JSKF1064)<br>Supervised by **Prof. Kang Jiang**

> - **Sensor Technology Integration and Data Fusion:** Integrated multi-sensors with IMU inertial navigation systems
>
> and developed a fusion algorithm, significantly improving system positioning accuracy in dynamic environments
>
> - **Data Analysis and Visualization:** Responsible for processing fused data, extracting key features for statistical
>
> analysis, and developing a data visualization interface.

------

## Undergraduate Projects

### May 2018 – Aug 2019  "Ergonomically Designed Multifunctional Intelligent Medical Bed"<br>

> <font color='red'>Team Leader</font><br> Supervised by *Dr. Zhenhua Yu*<br>
> Team members' majors: Mechanical Design Manufacturing and Automation, Industrial Engineering, Software Engineering, Information Management and Information Systems, .
>
> ### Overview<br>
>
> This project innovatively develops an **advanced medical care bed** by integrating **human factor engineering**, **big data analytics**, and **artificial intelligence** into existing medical and nursing bed designs.
>
> It combines **mechanical structure** with **electronic control** based on the **human-machine integrated model** to achieve **flexible and intelligent posture adjustment** using the human body posture parameters from the model. This allows the medical bed to provide functions like **massage**, **lifting**, and **vital signs monitoring**.
>
> <div style="text-align:center;">
> <figure style="display:inline-block; margin: 0 10px; max-width:45%;">
> <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Medical bed1.1.png" style="width:100%; height:auto;">
> <figcaption>Conceptual Diagram</figcaption>
> </figure>
> <figure style="display:inline-block; margin: 0 10px; max-width:45%;">
> <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate//Medical bed0.png" style="width:100%; height:auto;">
> <figcaption>Mechanical schematic</figcaption>
> </figure>
> </div>
>
> ### My Contributions
>
> #### 1.Key Innovations
>
> The bed surface consists of a **matrix of actuators** evenly distributed to effectively disperse pressure on the human body. 
>
> * When a patient lies on the bed, **pressure sensors** embedded in the actuators can collect and feedback real-time user position data to the cloud. 
> * The actuators are **designed based on human factor** principles to precisely conform to different body parts. 
>
> Underneath, **multiple stepper motors** drive cams and gears to translate continuous rotation into orderly actuator movements. **By rising and lowering at differential speeds**, the actuators induce continuous motions on specific body parts.
>
> #### 2.Enabling Mechanisms
>
> * **Motors** also power the primary and secondary shafts to enable the bed's functions. 
>     * The primary shaft goes through a belt and bevel gear to change direction, allowing **axial rotation** of the bed. 
>     * The secondary shaft connects to a **gear train** for orbital motion around the bed.
> * **Inclination** of the bed is enabled by the tilt mechanism on the bed frame, working with a linear actuator and motor. 
> * Additionally, an incomplete large spur gear combined with a rack actively lifts and lowers groups of actuators for targeted adjustment according to body needs.
>
> <div style="text-align:center;">
>     <figure style="display:inline-block; margin: 0 10px; max-width:30%;">
>         <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Medical bed2.1.png" style="width:100%; height:auto;">
>         <figcaption>Base and bed frame model</figcaption>
>     </figure>
>     <figure style="display:inline-block; margin: 0 10px; max-width:30%;">
>         <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Medical bed2.2.png" style="width:50%; height:auto;">
>         <figcaption>Gear and push rod assembly</figcaption>
>     </figure>
>     <figure style="display:inline-block; margin: 0 10px; max-width:30%;">
>         <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Medical bed2.3.png" style="width:100%; height:auto;">
>         <figcaption>Bed frame state diagram</figcaption>
>     </figure>
> </div>

### Jun 2018 – May 2019  "Intelligent Robots——Combat Robot "<br>

> ### Overview <br>
>
> <font color='red'>Program designer</font> <br>As a member of the intelligent robot project team (only 3 candidates), I was fully involved in the development of a sophisticated combat robot named "Pioneer." As the chief software architect of this project, I spearheaded the entire programming and functional implementation of the robot, with a particular emphasis on the development of its core logic: autonomous patrolling, enemy detection and attack strategies, and evasion and disguise mechanisms. Ultimately, we fabricated two prototypes of "Pioneer" and participated in the finals of the Intelligent Robotics Competition.
>
> <div style="text-align:center;">
> <figure style="display:inline-block; margin: 0 10px; max-width:45%;">
>   <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Robot1.png" style="width:100%; height:auto;">
>   <figcaption>Camouflage in dark conditions</figcaption>
> </figure>
> <figure style="display:inline-block; margin: 0 10px; max-width:45%;">
>   <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Robot2.png" style="width:100%; height:auto;">
>   <figcaption>Safety zone patrol</figcaption>
> </figure>
> </div>
> ### My Contributions
> 1. Architected the software system and hardware-software integration for Pioneer based on key competition requirements like the arena dimensions, weight limits, and scoring mechanics. This involved close collaboration with the mechanical and electrical engineers in the team.
> 2. Created autonomous control algorithms enabling Pioneer to intelligently navigate around the arena without falling off, using data from infrared and analog sensors. The algorithms had to be robust to sensor noise and uncertainties.  
> 3. Developed opponent search-and-attack logic by fusing inputs from multiple infrared rangefinders to reliably detect and lock on to enemy robots. This included aiming routines to align our robot's shovel perfectly for maximum pushing power.  
> 4. Optimized the software for real-time performance and responsiveness during battles. This was challenging due to the complex state transitions required between exploration, attack, and self-preservation modes.
> 5. Led the strategy for integrating and testing the complete robotic system. Coordinated with team members to troubleshoot issues like PCB failures or mechanical alignment problems.  
>
> <div style="text-align:center;">
>  <figure style="display:inline-block; margin: 0 10px; max-width:45%;">
>      <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Robot3.png" style="width:100%; height:auto;">
>      <figcaption>Camouflage in dark conditions</figcaption>
>  </figure>
>  <figure style="display:inline-block; margin: 0 10px; max-width:45%;">
>      <img src="https://GeruiXu.github.io/mypaper/Projects/Undergraduate/Robot4.png" style="width:100%; height:auto;">
>      <figcaption>Safety zone patrol</figcaption>
>  </figure>
> </div>
>
> ### Outcome
>
> In the competition, "Pioneer" excelled, reliably exploring over 90% of the arena and defeating two opposing robots with coordinated attack logic using just one unit. Our emerging team stood out amidst fierce competition from seasoned teams nationwide, reaffirming the efficacy of the software system I developed for "Pioneer." This project enhanced my skills in robot algorithms, software architecture, hardware-software integration, and leading engineering teams.

